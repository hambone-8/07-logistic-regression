{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression exercise with Titanic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "- Data from Kaggle's Titanic competition: [data](https://github.com/justmarkham/DAT8/blob/master/data/titanic.csv), [data dictionary](https://www.kaggle.com/c/titanic/data)\n",
    "- **Goal**: Predict survival based on passenger characteristics\n",
    "- `titanic.csv` is already in our repo, so there is no need to download the data from the Kaggle website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.194238Z",
     "start_time": "2021-07-22T05:59:49.422737Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the other modules you might need\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read the data into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.237648Z",
     "start_time": "2021-07-22T05:59:54.196812Z"
    }
   },
   "outputs": [],
   "source": [
    "#url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/titanic.csv'\n",
    "\n",
    "url = '../../data/titanic.csv'\n",
    "titanic_df = pd.read_csv(url, index_col='PassengerId')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create X and y\n",
    "\n",
    "Define **Pclass** and **Parch** as the features, and **Survived** as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.252909Z",
     "start_time": "2021-07-22T05:59:54.248523Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up data\n",
    "X = titanic_df[['Pclass', 'Parch']]\n",
    "y = titanic_df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.264183Z",
     "start_time": "2021-07-22T05:59:54.257557Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up train and test data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Fit a logistic regression model and examine the coefficients\n",
    "\n",
    "Confirm that the coefficients make intuitive sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.282032Z",
     "start_time": "2021-07-22T05:59:54.267435Z"
    }
   },
   "outputs": [],
   "source": [
    "# build a logistic regression model\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Make predictions on the testing set and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.291056Z",
     "start_time": "2021-07-22T05:59:54.284265Z"
    }
   },
   "outputs": [],
   "source": [
    "# class predictions (not predicted probabilities)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.310097Z",
     "start_time": "2021-07-22T05:59:54.294279Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate classification accuracy\n",
    "\n",
    "acc = lr.score(X_test,y_test)\n",
    "\n",
    "print(f'Accuracy: {acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Compare your testing accuracy to the null accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.336122Z",
     "start_time": "2021-07-22T05:59:54.323376Z"
    }
   },
   "outputs": [],
   "source": [
    "# this works regardless of the number of classes\n",
    "# We need to determine the most frequent class in the test data.\n",
    "test_df = pd.DataFrame(y_test)\n",
    "test_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.727985Z",
     "start_time": "2021-07-22T05:59:54.353924Z"
    }
   },
   "outputs": [],
   "source": [
    "# this only works for binary classification problems coded as 0/1\n",
    "y_null = np.zeros_like(y_test)\n",
    "\n",
    "print(f'Null Accuracy: {np.mean(y_test == y_null)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative approach\n",
    "\n",
    "y_null = 1 - y_test.mean()\n",
    "print(f'Null Accuracy: {np.mean(y_test == y_null)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix of Titanic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.748369Z",
     "start_time": "2021-07-22T05:59:54.733474Z"
    }
   },
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "\n",
    "# print confusion matrix - remember the order of elements in the confusion matrix\n",
    "\n",
    "def_confusion = np.array(\n",
    "        [['tn', 'fp'],\n",
    "         ['fn', 'tp']])\n",
    "\n",
    "print(f'Confusion Matrix: (defined) \\n {def_confusion}')\n",
    "print()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Confusion Matrix: \\n {cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.761672Z",
     "start_time": "2021-07-22T05:59:54.752328Z"
    }
   },
   "outputs": [],
   "source": [
    "# unravel the confusion matrix - \n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.772848Z",
     "start_time": "2021-07-22T05:59:54.765672Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the sensitivity\n",
    "sensitivity = tp/(tp + fn)\n",
    "print(f'Sensitivity: {sensitivity}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.790444Z",
     "start_time": "2021-07-22T05:59:54.784279Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the specificity\n",
    "specificity = tn/(tn + fp)\n",
    "print(f'Specificity: {specificity}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:54.812951Z",
     "start_time": "2021-07-22T05:59:54.801438Z"
    }
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities - use y_pred_prob as your variable\n",
    "y_pred_prob = lr.predict_proba(X_test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:55.462921Z",
     "start_time": "2021-07-22T05:59:54.827516Z"
    }
   },
   "outputs": [],
   "source": [
    "# histogram of predicted probabilities\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred_prob)\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Predicted probability of survival')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:55.471447Z",
     "start_time": "2021-07-22T05:59:55.466346Z"
    }
   },
   "outputs": [],
   "source": [
    "# increase sensitivity by lowering the threshold for predicting survival\n",
    "y_pred_sens = y_pred_prob > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:55.482261Z",
     "start_time": "2021-07-22T05:59:55.475058Z"
    }
   },
   "outputs": [],
   "source": [
    "# old confusion matrix\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:55.493497Z",
     "start_time": "2021-07-22T05:59:55.484706Z"
    }
   },
   "outputs": [],
   "source": [
    "# new confusion matrix\n",
    "cm_new = confusion_matrix(y_test, y_pred_sens)\n",
    "cm_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:55.513222Z",
     "start_time": "2021-07-22T05:59:55.499121Z"
    }
   },
   "outputs": [],
   "source": [
    "# new sensitivity (higher than before)\n",
    "tns, fps, fns, tps  = cm_new.ravel()\n",
    "sens = tps/(tps + fns)\n",
    "\n",
    "print(f'Original Sensitivity: {sensitivity}')\n",
    "print(f'     New Sensitivity: {sens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:55.527037Z",
     "start_time": "2021-07-22T05:59:55.517571Z"
    }
   },
   "outputs": [],
   "source": [
    "# new specificity (lower than before)\n",
    "specs= tns/(tns + fps)\n",
    "print(f'Original Specificity: {specificity}')\n",
    "print(f'     New Specificity: {specs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What did we prioritze when we lowered the threshold for survivability? That is, what confusion matrix element did we optimize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T05:59:55.537202Z",
     "start_time": "2021-07-22T05:59:55.532112Z"
    }
   },
   "source": [
    "**answer** - improving sensitivity reduces the number of False Positives. In this case, it reduces the number of people predicted to survive, even though they did not survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

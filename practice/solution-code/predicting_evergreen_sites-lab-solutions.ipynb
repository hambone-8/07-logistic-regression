{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Predicting \"Greenness\" Of Content\n",
    "\n",
    "_Authors: Joseph Nelson (DC), Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This dataset comes from [stumbleupon](https://www.stumbleupon.com/), a web page recommender and was made available [here](https://www.kaggle.com/c/stumbleupon/download/train.tsv)\n",
    "\n",
    "A description of the columns is below\n",
    "\n",
    "FieldName|Type|Description\n",
    "---------|----|-----------\n",
    "url|string|Url of the webpage to be classified\n",
    "urlid|integer| StumbleUpon's unique identifier for each url\n",
    "boilerplate|json|Boilerplate text\n",
    "alchemy_category|string|Alchemy category (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "alchemy_category_score|double|Alchemy category score (per the publicly available Alchemy API found at www.alchemyapi.com)\n",
    "avglinksize| double|Average number of words in each link\n",
    "commonLinkRatio_1|double|# of links sharing at least 1 word with 1 other links / # of links\n",
    "commonLinkRatio_2|double|# of links sharing at least 1 word with 2 other links / # of links\n",
    "commonLinkRatio_3|double|# of links sharing at least 1 word with 3 other links / # of links\n",
    "commonLinkRatio_4|double|# of links sharing at least 1 word with 4 other links / # of links\n",
    "compression_ratio|double|Compression achieved on this page via gzip (measure of redundancy)\n",
    "embed_ratio|double|Count of number of <embed> usage\n",
    "frameBased|integer (0 or 1)|A page is frame-based (1) if it has no body markup but have a frameset markup\n",
    "frameTagRatio|double|Ratio of iframe markups over total number of markups\n",
    "hasDomainLink|integer (0 or 1)|True (1) if it contains an <a> with an url with domain\n",
    "html_ratio|double|Ratio of tags vs text in the page\n",
    "image_ratio|double|Ratio of <img> tags vs text in the page\n",
    "is_news|integer (0 or 1) | True (1) if StumbleUpon's news classifier determines that this webpage is news\n",
    "lengthyLinkDomain| integer (0 or 1)|True (1) if at least 3 <a> 's text contains more than 30 alphanumeric characters\n",
    "linkwordscore|double|Percentage of words on the page that are in hyperlink's text\n",
    "news_front_page| integer (0 or 1)|True (1) if StumbleUpon's news classifier determines that this webpage is front-page news\n",
    "non_markup_alphanum_characters|integer| Page's text's number of alphanumeric characters\n",
    "numberOfLinks|integer Number of <a>|markups\n",
    "numwords_in_url| double|Number of words in url\n",
    "parametrizedLinkRatio|double|A link is parametrized if it's url contains parameters or has an attached onClick event\n",
    "spelling_errors_ratio|double|Ratio of words not found in wiki (considered to be a spelling mistake)\n",
    "label|integer (0 or 1)|User-determined label. Either evergreen (1) or non-evergreen (0); available for train.tsv only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "# set max printout options for pandas:\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "- Note it is a `.tsv` file and has a tab separator instead of comma.\n",
    "- Clean the `is_news` column.\n",
    "- Make two new columns, `title` and `body`, from the `boilerplate` column.\n",
    "\n",
    "> **Note:** The `boilerplate` column is in json dictionary format. You can use the `json.loads()` function from the `json` module to convert this into a python dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evergreen_tsv = '../../data/evergreen_sites.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(evergreen_tsv, sep='\\t', na_values={'is_news' : '?'}).fillna(0)\n",
    "\n",
    "# Extract the title and body from the boilerplate JSON text\n",
    "data['title'] = data.boilerplate.map(lambda x: json.loads(x).get('title', ''))\n",
    "data['body'] = data.boilerplate.map(lambda x: json.loads(x).get('body', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What are 'evergreen' sites?\n",
    "- These are websites that always relevant like recipes or reviews (as opposed to current events).\n",
    "- Stored as a binary indicator in the `label` column.\n",
    "- Look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['title', 'label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Does being a news site affect green-ness?\n",
    "\n",
    "**3.A Investigate with plots/EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((data.groupby('is_news')[['label']].mean()))\n",
    "sns.factorplot(x='is_news', y='label', data=data, kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.B Test the hypothesis with a logistic regression using statsmodels.**\n",
    "\n",
    "> **Hint:** The `sm.logit` function from `statsmodels.formula.api` will perform a logistic regression using a formula string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = data[['label','is_news']]\n",
    "\n",
    "news_model = sm.logit(\"label ~ is_news\", data=news_data).fit()\n",
    "news_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.C Interpret the results of your model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The effect of being a news site on evergreen status is insignificant.\n",
    "# More formally, we would accept the null hypothesis that news sites and\n",
    "# non-news sites have equal probability of being evergreen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Does the website category affect green-ness?\n",
    "\n",
    "**4.A Investigate with plots/EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ? and unknown should be the same category:\n",
    "data['alchemy_category'] = data.alchemy_category.map(lambda x: 'unknown' if x == '?' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((data.groupby('alchemy_category')[['label']].mean()))\n",
    "\n",
    "sns.factorplot(x='alchemy_category', y='label', \n",
    "               data=data, kind='bar', aspect=3).set_xticklabels(rotation=45, horizontalalignment='right')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.B Test the hypothesis with a logistic regression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = sm.logit(\"label ~ C(alchemy_category, Treatment(reference='unknown'))\", data=data).fit()\n",
    "cat_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.C Interpret the model results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many of the categories appear to have a significant effect on the likelihood of evergreen\n",
    "# status. Note that I have set the reference category to be unknown. This is wrapped into\n",
    "# the intercept term. These categories must be interpreted as significantly different from\n",
    "# unknown or not.\n",
    "\n",
    "# Positive predictors of evergreen vs. unknown:\n",
    "# 1. Business\n",
    "# 2. Health\n",
    "# 3. Recreation\n",
    "\n",
    "# Negative predictors of evergreen vs. unkown:\n",
    "# 1. Arts and entertainment\n",
    "# 2. Computer and internet\n",
    "# 3. Gaming\n",
    "# 4. Sports\n",
    "\n",
    "# The rest of the categories are not significantly different than the unkown category\n",
    "# in their probability of being evergreen or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Does the image ratio affect green-ness?\n",
    "\n",
    "**5.A Investigate with plots/EDA.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.image_ratio, bins=30, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qcut can divide things up by quantile - in this case into 5 bins\n",
    "data['image_ratio_qbinned'] = pd.qcut(data['image_ratio'], 5)\n",
    "\n",
    "sns.factorplot('image_ratio_qbinned', 'label', data=data, aspect=2).set_xticklabels(rotation=45, \n",
    "                                                                                  horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.B Test the hypothesis using a logistic regression.**\n",
    "\n",
    "> **Note**: It is worth thinking about how to best represent this variable. It may not be wise to input the image ratio as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a model using image ratio alone (ignoring the apparent nonlinear effect and skewed distribution):\n",
    "image_model = sm.logit(\"label ~ image_ratio\", data=data).fit()\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image ratio to percentiles (this is what qcut is representing in bins):\n",
    "# you can use the scipy.stats.percentileofscore for this:\n",
    "from scipy import stats\n",
    "\n",
    "data['image_ratio_pctl'] = data.image_ratio.map(lambda x: stats.percentileofscore(data.image_ratio.values, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.image_ratio_pctl, bins=30, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the image_ratio_percentile instead\n",
    "# this is still ignoring the nonlinearity we wee in the plot above!\n",
    "image_model = sm.logit(\"label ~ image_ratio_pctl\", data=data).fit()\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model with the percentile and the percentile squared (quadratic effect)\n",
    "# This will let us model that inverse parabola\n",
    "# Note: statsmodels formulas can take numpy functions!\n",
    "image_model = sm.logit(\"label ~ image_ratio_pctl + np.power(image_ratio_pctl, 2)\", data=data).fit()\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.C Interpret the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once it's modeled well (convert the image ratio to percentiles and include\n",
    "# a quadratic term) we can see these significant effects:\n",
    "\n",
    "# 1. There is a positive effect of the image ratio percentile score (its rank \n",
    "# across image_ratios)\n",
    "\n",
    "# 2. There is a negative quadratic effect of image ratio. That is to say, at\n",
    "# a certain point the squared term of image_ratio_pctl overtakes the linear\n",
    "# term. The highest probability of evergreen sites have image ratios in the\n",
    "# median range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fit a logistic regression with multiple predictors.\n",
    "- The choice of predictors is up to you. Test features you think may be valuable to predict evergreen status.\n",
    "- Do any EDA you may need.\n",
    "- Interpret the coefficients of the model.\n",
    "\n",
    "> **Tip:** [This pdf is very useful for an overview of interpreting logistic regression coefficients.](https://www.unm.edu/~schrader/biostat/bio2/Spr06/lec11.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the distribution of html_ratio\n",
    "sns.distplot(data.html_ratio, bins=30, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut can divide things up into linear bins - in this case into 5 bins\n",
    "data['html_ratio_binned'] = pd.cut(data['html_ratio'], 5)\n",
    "sns.factorplot('html_ratio_binned', 'label', data=data, aspect=2).set_xticklabels(rotation=45, \n",
    "                                                                                 horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut can divide things up into linear bins - in this case into 5 bins\n",
    "data['html_ratio_qbinned'] = pd.qcut(data['html_ratio'], 5)\n",
    "sns.factorplot('html_ratio_qbinned', 'label', data=data, aspect=2).set_xticklabels(rotation=45, \n",
    "                                                                                 horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['html_ratio_pctl'] = data.html_ratio.map(lambda x: stats.percentileofscore(data.html_ratio.values, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see scipy puts percentiles from 0-100: important for interpreting coefs\n",
    "data.html_ratio_pctl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_len(x):\n",
    "    try:\n",
    "        return len(x.split())\n",
    "    except:\n",
    "        return 0.\n",
    "\n",
    "# calculate the number of words in the title and plot distribution\n",
    "data['title_words'] = data.title.map(title_len)\n",
    "sns.distplot(data.title_words, bins=30, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_words_binned'] = pd.cut(data['title_words'], 10)\n",
    "\n",
    "sns.factorplot('title_words_binned', 'label', data=data, aspect=2).set_xticklabels(rotation=45, \n",
    "                                                                                 horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a model with the image ratio percentile, html ratio, and title length\n",
    "f = '''\n",
    "label ~ image_ratio_pctl + np.power(image_ratio_pctl, 2) + html_ratio_pctl + title_words\n",
    "'''\n",
    "model = sm.logit(f, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponentiate the coefficients to get the odds ratio:\n",
    "np.exp(model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We've got all significant effects on our predictors here.\n",
    "# Must interpret them as odds ratios.\n",
    "# 1. for a 1 percentile increase in image_ratio, there is a ~1.03x increase in the odds of evergreen\n",
    "# 2. for a 1 unit increase in image_ratio_pctl**2, there is a ~0.999x decrease in the odds of evergreen\n",
    "# 3. for a 1 percentile increase in html_ratio, there is a ~0.992x decrease in the odds of evergreen\n",
    "# 4. for a 1 word increase in the length of the title, there is a ~0.956x decrease in the odds of evergreen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
